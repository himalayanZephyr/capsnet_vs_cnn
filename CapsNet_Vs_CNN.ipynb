{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CapsNet_Vs_CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "xi-QfRmbbJri",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TlwVu_j-bipn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0ac7ebd-bfc4-40c9-e870-76c1349be23d"
      },
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fmfoEikFieEw",
        "colab_type": "code",
        "outputId": "1839b0d4-0a51-4287-dd15-084d5f715a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data as mnist_data\n",
        "\n",
        "# For MNIST\n",
        "mnist = mnist_data.read_data_sets(\"MNIST_data/\", one_hot= True)\n",
        "\n",
        "# For Fashion MNIST\n",
        "# mnist = input_data.read_data_sets('data/fashion', source_url='http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/', one_hot= True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-74d0a907ffa6>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a1u3LMSbckbL",
        "colab_type": "code",
        "outputId": "26b664a8-4a82-4a3d-ab8f-42415022fe2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "cell_type": "code",
      "source": [
        "#==================== BASELINE CNN =========================#\n",
        "\n",
        "# to reset the Tensorflow default graph\n",
        "tf.reset_default_graph()\n",
        "\n",
        "########################################\n",
        "# define variables and placeholders\n",
        "########################################\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, 28, 28, 1), name=\"X\")\n",
        "Y = tf.placeholder(tf.float32, shape=(None, 10), name=\"Y\")\n",
        "\n",
        "# variable learning rate\n",
        "\n",
        "step = tf.placeholder(tf.int32)\n",
        "lr = 0.0001 +  tf.train.exponential_decay(0.005, step, 2000, 1/math.e)\n",
        "\n",
        "pkeep = tf.placeholder(tf.float32)\n",
        "\n",
        "should_drop = tf.placeholder(tf.bool)\n",
        "\n",
        "\n",
        "\n",
        "########################################\n",
        "# build the model\n",
        "########################################\n",
        "\n",
        "conv1 = tf.layers.conv2d(inputs=X, filters=256, kernel_size=[5, 5], strides=(1,1), padding=\"valid\", activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False), bias_initializer='zeros')\n",
        "conv2 = tf.layers.conv2d(inputs=conv1, filters=256, kernel_size=[5, 5], strides=(1,1), padding=\"valid\", activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False), bias_initializer='zeros')\n",
        "conv3 = tf.layers.conv2d(inputs=conv2, filters=128, kernel_size=[5, 5], strides=(1,1), padding=\"valid\", activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False), bias_initializer='zeros')\n",
        "\n",
        "flat_dims = conv3.shape[1] * conv3.shape[2] * conv3.shape[3] \n",
        "\n",
        "flat = tf.reshape(conv3, [-1, flat_dims])\n",
        "\n",
        "hidden1 = tf.layers.dense(inputs=flat, units=328, activation=tf.nn.relu)\n",
        "hidden2 = tf.layers.dense(inputs=hidden1, units=192, activation=tf.nn.relu)\n",
        "dropout = tf.layers.dropout(inputs=hidden2, rate=0.25, training=should_drop)\n",
        "\n",
        "output = tf.layers.dense(inputs=dropout, units=10)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################\n",
        "# define the Loss function\n",
        "########################################\n",
        "cross_entropy = tf.losses.softmax_cross_entropy(Y, output)\n",
        "cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
        "\n",
        "\n",
        "########################################\n",
        "# define accuracy\n",
        "########################################\n",
        "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
        "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(output, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "\n",
        "########################################\n",
        "# training the model\n",
        "########################################\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
        "train_step = optimizer.minimize(cross_entropy)\n",
        "\n",
        "########################################\n",
        "# execute the model\n",
        "########################################\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "steps = 5500 #5500*100 = 55000 * 10\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  start_time = time.time()\n",
        "  for i in range(steps):\n",
        "    batch_X, batch_Y = mnist.train.next_batch(100)\n",
        "    \n",
        "    batch_X = np.reshape(batch_X,[100,28,28,1])\n",
        "    \n",
        "    _,cost = sess.run([train_step,cross_entropy], feed_dict={X: batch_X, Y: batch_Y, step: i, pkeep:0.75, should_drop:True})\n",
        "    \n",
        "    if i%200 == 0:\n",
        "      print(\"iteration {0}, cost is {1}\".format(i, cost))\n",
        "  \n",
        "  end_time = time.time()\n",
        "  n_test_subset = 5000\n",
        "  test_images = mnist.test.images[0:n_test_subset]\n",
        "  test_labels = mnist.test.labels[0:n_test_subset]\n",
        "  \n",
        "  print(test_images.shape)\n",
        "  test_data={X: np.reshape(test_images,[n_test_subset,28,28,1]), Y: test_labels, pkeep:1.0, should_drop:False}\n",
        "  \n",
        "  print(\"Time is {}\".format(end_time-start_time))\n",
        "  \n",
        "\n",
        "  acc = sess.run([accuracy], feed_dict=test_data)\n",
        "  print(\"Accuracy on the test set is: {0}\".format(acc))\n",
        "  \n",
        "    "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0, cost is 230.46170043945312\n",
            "iteration 200, cost is 18.074941635131836\n",
            "iteration 400, cost is 21.10568618774414\n",
            "iteration 600, cost is 5.552218914031982\n",
            "iteration 800, cost is 3.175575017929077\n",
            "iteration 1000, cost is 5.1382975578308105\n",
            "iteration 1200, cost is 1.7702337503433228\n",
            "iteration 1400, cost is 4.496580600738525\n",
            "iteration 1600, cost is 1.375048279762268\n",
            "iteration 1800, cost is 0.14027920365333557\n",
            "iteration 2000, cost is 0.07626865059137344\n",
            "iteration 2200, cost is 4.141570568084717\n",
            "iteration 2400, cost is 0.15379801392555237\n",
            "iteration 2600, cost is 0.3893683850765228\n",
            "iteration 2800, cost is 0.41190922260284424\n",
            "iteration 3000, cost is 0.6754037141799927\n",
            "iteration 3200, cost is 0.9176600575447083\n",
            "iteration 3400, cost is 0.6081249117851257\n",
            "iteration 3600, cost is 0.3668578863143921\n",
            "iteration 3800, cost is 0.0016129912110045552\n",
            "iteration 4000, cost is 0.06055937707424164\n",
            "iteration 4200, cost is 0.0011101235868409276\n",
            "iteration 4400, cost is 0.04544683173298836\n",
            "iteration 4600, cost is 0.044591374695301056\n",
            "iteration 4800, cost is 0.07911025732755661\n",
            "iteration 5000, cost is 0.005988096818327904\n",
            "iteration 5200, cost is 0.017850449308753014\n",
            "iteration 5400, cost is 0.009707524441182613\n",
            "(5000, 784)\n",
            "Time is 550.49445271492\n",
            "Accuracy on the test set is: [0.9842]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6wagIoc5-rJn",
        "colab_type": "code",
        "outputId": "4d6345de-c615-4199-8dc7-04793e108ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "cell_type": "code",
      "source": [
        "! rm -rf CapsNet-Tensorflow\n",
        "! git clone https://github.com/himalayanZephyr/CapsNet-Tensorflow.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CapsNet-Tensorflow'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 587 (delta 12), reused 0 (delta 0), pack-reused 563\u001b[K\n",
            "Receiving objects: 100% (587/587), 1.60 MiB | 1.78 MiB/s, done.\n",
            "Resolving deltas: 100% (294/294), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Ls2gPM6_K1c",
        "colab_type": "code",
        "outputId": "343d2be2-a3f7-4e57-cbb1-eaaace4914c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4e1Ck_FfA-kX",
        "colab_type": "code",
        "outputId": "b7377c69-4543-428a-d644-3f6370f7a2ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "# For MNIST\n",
        "!python CapsNet-Tensorflow/download_data.py\n",
        "\n",
        "# For Fashion MNIST\n",
        "# !python CapsNet-Tensorflow/download_data.py --dataset fashion-mnist --save_to data/fashion-mnist"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> Downloading train-images-idx3-ubyte.gz 100.1%\n",
            "Successfully Downloaded train-images-idx3-ubyte.gz\n",
            "Extracting  train-images-idx3-ubyte.gz\n",
            "Successfully extracted\n",
            "\n",
            ">> Downloading train-labels-idx1-ubyte.gz 113.5%\n",
            "Successfully Downloaded train-labels-idx1-ubyte.gz\n",
            "Extracting  train-labels-idx1-ubyte.gz\n",
            "Successfully extracted\n",
            "\n",
            ">> Downloading t10k-images-idx3-ubyte.gz 100.4%\n",
            "Successfully Downloaded t10k-images-idx3-ubyte.gz\n",
            "Extracting  t10k-images-idx3-ubyte.gz\n",
            "Successfully extracted\n",
            "\n",
            ">> Downloading t10k-labels-idx1-ubyte.gz 180.4%\n",
            "Successfully Downloaded t10k-labels-idx1-ubyte.gz\n",
            "Extracting  t10k-labels-idx1-ubyte.gz\n",
            "Successfully extracted\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DSYPbbND_qrG",
        "colab_type": "code",
        "outputId": "6ee27aa4-ca49-498f-ac6d-ee8e03d07a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1381
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# For MNIST\n",
        "!python CapsNet-Tensorflow/main.py\n",
        "\n",
        "# For Fashion MNIST\n",
        "# !python CapsNet-Tensorflow/main.py --dataset fashion-mnist\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Training time is {}\".format(end_time-start_time))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/CapsNet-Tensorflow/utils.py:89: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:374: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:320: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /content/CapsNet-Tensorflow/utils.py:94: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /content/CapsNet-Tensorflow/capsNet.py:85: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From CapsNet-Tensorflow/main.py:123: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "2019-02-17 17:17:32.368204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-02-17 17:17:32.368439: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2d5a7e0 executing computations on platform Host. Devices:\n",
            "2019-02-17 17:17:32.368496: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-02-17 17:17:32.466344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-02-17 17:17:32.467022: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2d5ac00 executing computations on platform CUDA. Devices:\n",
            "2019-02-17 17:17:32.467058: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-02-17 17:17:32.467408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-02-17 17:17:32.467492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-02-17 17:17:32.769626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-02-17 17:17:32.769676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-02-17 17:17:32.769694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-02-17 17:17:32.769993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10754 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "tcmalloc: large alloc 1233903616 bytes == 0x5d8a6000 @  0x7fca24060615 0x57b7f5 0x5858df 0x5a4aab 0x52e638 0x502e0c 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d\n",
            "tcmalloc: large alloc 1542381568 bytes == 0xa7164000 @  0x7fca24060615 0x57b7f5 0x5858df 0x5a4aab 0x52e638 0x502e0c 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d\n",
            "\n",
            "Note: all of results will be saved to directory: results\n",
            "Training for epoch 0/10:\n",
            "  0%|                                          | 0/550 [00:00<?, ?b/s]2019-02-17 17:18:19.018058: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "Training for epoch 1/10:\n",
            "Training for epoch 2/10:\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'Tensor' object has no attribute 'to_proto'\n",
            "Training for epoch 3/10:\n",
            "Training for epoch 4/10:\n",
            "Training for epoch 5/10:\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'Tensor' object has no attribute 'to_proto'\n",
            "Training for epoch 6/10:\n",
            "Training for epoch 7/10:\n",
            "Training for epoch 8/10:\n",
            "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'Tensor' object has no attribute 'to_proto'\n",
            "Training for epoch 9/10:\n",
            "Training time is 1595.737857580185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FOL1kWRPexKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1162
        },
        "outputId": "b82852f1-3d0f-4858-aab2-febb00725d8e"
      },
      "cell_type": "code",
      "source": [
        "#====================TEST ACCURACY ========================#\n",
        "\n",
        "\n",
        "# For MNIST\n",
        "!python CapsNet-Tensorflow/main.py --is_training=False\n",
        "\n",
        "# For Fashion MNIST\n",
        "# !python CapsNet-Tensorflow/main.py --dataset fashion-mnist --is_training=False"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/CapsNet-Tensorflow/utils.py:89: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:374: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:320: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /content/CapsNet-Tensorflow/utils.py:94: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /content/CapsNet-Tensorflow/capsNet.py:85: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From CapsNet-Tensorflow/main.py:123: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "(5000, 28, 28, 1) (5000,) 50\n",
            "2019-02-17 17:45:09.284051: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-02-17 17:45:09.284307: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x234da20 executing computations on platform Host. Devices:\n",
            "2019-02-17 17:45:09.284344: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-02-17 17:45:09.381268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-02-17 17:45:09.381981: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x234e7e0 executing computations on platform CUDA. Devices:\n",
            "2019-02-17 17:45:09.382019: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-02-17 17:45:09.382514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-02-17 17:45:09.382572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-02-17 17:45:09.681842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-02-17 17:45:09.681933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-02-17 17:45:09.681952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-02-17 17:45:09.682267: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-02-17 17:45:09.682326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10754 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "tcmalloc: large alloc 1233903616 bytes == 0x51210000 @  0x7f305c93a615 0x57b7f5 0x5858df 0x5a4aab 0x52e638 0x502e0c 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d\n",
            "tcmalloc: large alloc 1542381568 bytes == 0x9aace000 @  0x7f305c93a615 0x57b7f5 0x5858df 0x5a4aab 0x52e638 0x502e0c 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x502209 0x502f3d\n",
            "2019-02-17 17:45:55.232234: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "Test accuracy has been saved to results/test_acc.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fHPpKDVPAnZv",
        "colab_type": "code",
        "outputId": "f8df7d5d-ec95-4f76-f1be-a9600f755e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "#=================== Printing Accuracy ====================#\n",
        "\n",
        "import csv\n",
        "\n",
        "with open('results/test_acc.csv', 'r') as csvFile:\n",
        "    reader = csv.reader(csvFile)\n",
        "    for row in reader:\n",
        "      print(row)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['test_acc']\n",
            "['0.991']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}